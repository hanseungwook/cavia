{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils\n",
    "import tasks_sine, tasks_celebA\n",
    "from models import CaviaModel, Model_Active, Encoder_Decoder, Onehot_Encoder\n",
    "from logger import Logger\n",
    "import IPython\n",
    "\n",
    "import random\n",
    "\n",
    "def set_seed(seed, cudnn=True):\n",
    "    \"\"\"\n",
    "    Seed everything we can!\n",
    "    Note that gym environments might need additional seeding (env.seed(seed)),\n",
    "    and num_workers needs to be set to 1.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # note: the below slows down the code but makes it reproducible\n",
    "    if (seed is not None) and cudnn:\n",
    "        torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/huh/miniconda3/envs/bfs/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class manual_optim():\n",
    "    def __init__(self, param_list, lr):\n",
    "        self.param_list = param_list\n",
    "        self.lr = lr\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for par in self.param_list:\n",
    "            par.grad = torch.zeros(par.data.shape)\n",
    "        \n",
    "    def step(self):\n",
    "    \n",
    "        for par in self.param_list:\n",
    "    #         par.grad = torch.autograd.grad(task_loss, par, create_graph= not first_order)[0] #not args.first_order)[0]\n",
    "            par.data = par.data - par.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_inner = 0.01\n",
    "first_order = True\n",
    "tasks_per_metaupdate = 1\n",
    "k_meta_train = 10\n",
    "k_meta_test = 10\n",
    "\n",
    "    \n",
    "def eval_model(model, context, inputs, target_fnc):\n",
    "    outputs = model(inputs, context)\n",
    "    targets = target_fnc(inputs)\n",
    "    return F.mse_loss(outputs, targets)\n",
    "\n",
    "def inner_update(model, task_train, target_fnc):\n",
    "    context = model.reset_context()\n",
    "    optim_inner = optim.SGD([context], lr_inner) \n",
    "#     optim_inner = manual_optim([context], lr_inner) \n",
    "    train_inputs = task_train.sample_inputs(k_meta_train, False)\n",
    "    for _ in range(1):\n",
    "        optim_inner.zero_grad()\n",
    "        task_loss = eval_model(model, context, train_inputs, target_fnc)\n",
    "        context.grad = torch.autograd.grad(task_loss, context, create_graph= not first_order)[0] #not args.first_order)[0]\n",
    "#         task_loss.backward(create_graph= True, retain_graph = False)\n",
    "        optim_inner.step()\n",
    "        \n",
    "        print(context.grad)\n",
    "        \n",
    "    return context \n",
    "\n",
    "\n",
    "def get_meta_loss( model, task_family, target_fnc):\n",
    "    meta_loss = 0\n",
    "    for t in range(tasks_per_metaupdate):\n",
    "        context = inner_update(model, task_family, target_fnc)\n",
    "        test_inputs = task_family.sample_inputs(k_meta_test, False)\n",
    "        meta_loss += eval_model(model, context, test_inputs, target_fnc)\n",
    "    return meta_loss / tasks_per_metaupdate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8015,  0.3827]])\n",
      "4.098099708557129\n"
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "\n",
    "MODEL = Model_Active\n",
    "model = MODEL(n_arch=[1,4,4,1],  n_context=2)\n",
    "\n",
    "meta_optimiser = optim.Adam(model.parameters(), 0.01)\n",
    "\n",
    "task_train = tasks_sine.RegressionTasksSinusoidal()\n",
    "target_functions = task_train.sample_tasks(tasks_per_metaupdate)[0]\n",
    "\n",
    "meta_optimiser.zero_grad()\n",
    "meta_loss = get_meta_loss( model, task_train, target_functions)\n",
    "meta_loss.backward()\n",
    "\n",
    "grad_norm = 0\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    grad_norm += param.grad.norm()\n",
    "\n",
    "print(grad_norm.item())\n",
    "\n",
    "\n",
    "# meta_optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([[-0.8015,  0.3827]])\n",
    "tensor([[-0.7947,  0.3880]])\n",
    "tensor([[-0.7878,  0.3930]])\n",
    "tensor([[-0.7808,  0.3978]])\n",
    "20.710269927978516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_meta_gradient(model, task_train, target_fnc):\n",
    "\n",
    "    train_inputs = task_train.sample_inputs(k_meta_train, False)\n",
    "    test_inputs = task_train.sample_inputs(k_meta_test, False)\n",
    "\n",
    "    context = model.reset_context()\n",
    "    for _ in range(4):\n",
    "        context = update_context(model, context, train_inputs, target_fnc)\n",
    "\n",
    "    loss_meta = eval_model(model, context, test_inputs, target_fnc)\n",
    "    return loss_meta\n",
    "\n",
    "\n",
    "def meta_backward( model, task_family, target_fnc):\n",
    "    loss_meta = 0\n",
    "    for t in range(tasks_per_metaupdate):\n",
    "        loss_meta += get_meta_gradient( model, task_family, target_fnc)\n",
    "    return loss_meta / tasks_per_metaupdate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.03557014465332\n"
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "\n",
    "MODEL = Model_Active\n",
    "model = MODEL(n_arch=[1,4,4,1],  n_context=2)\n",
    "\n",
    "meta_optimiser = optim.Adam(model.parameters(), 0.01)\n",
    "\n",
    "task_train = tasks_sine.RegressionTasksSinusoidal()\n",
    "target_functions = task_train.sample_tasks(tasks_per_metaupdate)[0]\n",
    "\n",
    "\n",
    "meta_optimiser.zero_grad()\n",
    "\n",
    "loss_meta = meta_backward( model, task_train, target_functions)\n",
    "loss_meta.backward()\n",
    "# \n",
    "grad_norm = 0\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    grad_norm += param.grad.norm()\n",
    "\n",
    "print(grad_norm.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.07114028930664\n",
    "8.922293663024902\n",
    "7.92586088180542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_per_metaupdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bfs] *",
   "language": "python",
   "name": "conda-env-bfs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
