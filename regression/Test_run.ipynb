{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from main_huh import main, get_args\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[2, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[13, 8, 3], k_batch_train=[13, 8, 3], k_batch_valid=[13, 8, 3], levels=3, log_interval=100, log_name='experiment', loss_logging_levels=[], lrs=[0.01, 0.01, 0.01], model_type='CAVIA', n_batch_test=[13, 8, 3], n_batch_train=[13, 8, 3], n_batch_valid=[13, 8, 3], n_contexts=[2, 2], n_iters=[3, 10, 100], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='mnist_lv2', test_interval=5, v_num=None, viz=False)\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "max_iters [3, 10, 5]\n",
      "train [7, 5, 11, 16, 4, 12, 20, 15]\n",
      "test [10, 14, 19, 22, 9, 8, 3, 6]\n",
      "valid [23, 0, 1, 13, 18, 2, 17, 21]\n",
      "train [14, 23, 15, 11, 16, 20, 17, 7]\n",
      "test [0, 19, 9, 12, 5, 1, 18, 2]\n",
      "valid [3, 21, 6, 4, 8, 10, 13, 22]\n",
      "train [0, 12, 15, 10, 8, 23, 21, 5]\n",
      "test [16, 4, 22, 14, 3, 13, 17, 9]\n",
      "valid [7, 1, 2, 6, 18, 11, 19, 20]\n",
      "train [3, 6, 7]\n",
      "train [12, 11, 13, 9, 23, 14, 1, 0]\n",
      "test [15, 3, 8, 10, 4, 6, 16, 18]\n",
      "valid [7, 17, 5, 19, 2, 20, 21, 22]\n",
      "train [9, 7, 0, 13, 5, 1, 17, 21]\n",
      "test [20, 16, 22, 19, 11, 3, 2, 8]\n",
      "valid [4, 14, 12, 15, 23, 10, 18, 6]\n",
      "train [23, 7, 9, 11, 18, 21, 6, 19]\n",
      "test [16, 1, 10, 0, 15, 22, 8, 14]\n",
      "valid [17, 12, 2, 13, 5, 20, 4, 3]\n",
      "test [4, 8, 2]\n",
      "train [22, 12, 1, 7, 21, 6, 4, 11]\n",
      "test [18, 2, 17, 15, 20, 10, 13, 9]\n",
      "valid [3, 19, 23, 16, 8, 0, 14, 5]\n",
      "train [14, 6, 0, 23, 5, 4, 22, 21]\n",
      "test [18, 10, 16, 8, 12, 19, 13, 15]\n",
      "valid [17, 2, 20, 1, 7, 9, 11, 3]\n",
      "train [19, 7, 2, 6, 10, 21, 4, 13]\n",
      "test [8, 23, 0, 5, 1, 17, 15, 3]\n",
      "valid [18, 16, 14, 11, 20, 12, 9, 22]\n",
      "valid [5, 0, 1]\n",
      "start model training\n",
      "outer-loop idx 0 test loss 0.08963257819414139\n",
      "Saving model\n",
      "outer-loop idx 1 test loss 0.0912279486656189\n",
      "Saving model\n",
      "outer-loop idx 2 test loss 0.08735904842615128\n",
      "Saving model\n",
      "outer-loop idx 3 test loss 0.08522636443376541\n",
      "Saving model\n",
      "outer-loop idx 4 test loss 0.08355680108070374\n",
      "Saving model\n",
      "outer-loop idx 5 test loss 0.08191555738449097\n",
      "Saving model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2c9fa0f90c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/main_huh.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# logger.log_hyperparams(hparams) # Commenting out b/c causing errors with logging hyperparameters of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Start train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/train_huh.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(hparams, logger)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msupertask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# grad_clip = hparams.clip ) #TODO: gradient clipping?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outer-loop idx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, task_list, level, optimizer, reset, return_outputs, prev_status, current_status, viz)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/lv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, level, status, optimizer, reset, return_outputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# evaluate on one mini-batch from test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# param_all[level] # for log_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_status\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Loss to be optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, task_list, level, optimizer, reset, return_outputs, prev_status, current_status, viz)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/lv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, level, status, optimizer, reset, return_outputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# evaluate on one mini-batch from test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# param_all[level] # for log_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_status\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Loss to be optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, task_list, level, optimizer, reset, return_outputs, prev_status, current_status, viz)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/lv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, level, status, optimizer, reset, return_outputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# evaluate on one mini-batch from test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cur_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mcur_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0mfirst_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mfirst_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#filter(lambda p: p.grad is not None, parameters):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    202\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_ = \"--task mnist_lv2 --n_contexts 2 2  --n_iters 3 10 100 --k_batch_train 13 8 3  --n_batch_train 13 8 3 --architecture 2 28 1  --test_interval 5 --private \" \n",
    "args = get_args(input_.split())\n",
    "print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[2, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[13, 8, 3], k_batch_train=[13, 8, 3], k_batch_valid=[13, 8, 3], levels=3, log_interval=100, log_name='experiment', loss_logging_levels=[], lrs=[0.01, 0.01, 0.01], model_type='CAVIA', n_batch_test=[13, 8, 3], n_batch_train=[13, 8, 3], n_batch_valid=[13, 8, 3], n_contexts=[2, 2], n_iters=[3, 10, 100], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='fmnist_lv2', test_interval=0, v_num=None, viz=False)\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "max_iters [3, 10, 100]\n",
      "train [7, 5, 11, 16, 4, 12, 20, 15]\n",
      "test [10, 14, 19, 22, 9, 8, 3, 6]\n",
      "valid [23, 0, 1, 13, 18, 2, 17, 21]\n",
      "train [14, 23, 15, 11, 16, 20, 17, 7]\n",
      "test [0, 19, 9, 12, 5, 1, 18, 2]\n",
      "valid [3, 21, 6, 4, 8, 10, 13, 22]\n",
      "train [0, 12, 15, 10, 8, 23, 21, 5]\n",
      "test [16, 4, 22, 14, 3, 13, 17, 9]\n",
      "valid [7, 1, 2, 6, 18, 11, 19, 20]\n",
      "train [3, 6, 7]\n",
      "train [12, 11, 13, 9, 23, 14, 1, 0]\n",
      "test [15, 3, 8, 10, 4, 6, 16, 18]\n",
      "valid [7, 17, 5, 19, 2, 20, 21, 22]\n",
      "train [9, 7, 0, 13, 5, 1, 17, 21]\n",
      "test [20, 16, 22, 19, 11, 3, 2, 8]\n",
      "valid [4, 14, 12, 15, 23, 10, 18, 6]\n",
      "train [23, 7, 9, 11, 18, 21, 6, 19]\n",
      "test [16, 1, 10, 0, 15, 22, 8, 14]\n",
      "valid [17, 12, 2, 13, 5, 20, 4, 3]\n",
      "test [4, 8, 2]\n",
      "train [22, 12, 1, 7, 21, 6, 4, 11]\n",
      "test [18, 2, 17, 15, 20, 10, 13, 9]\n",
      "valid [3, 19, 23, 16, 8, 0, 14, 5]\n",
      "train [14, 6, 0, 23, 5, 4, 22, 21]\n",
      "test [18, 10, 16, 8, 12, 19, 13, 15]\n",
      "valid [17, 2, 20, 1, 7, 9, 11, 3]\n",
      "train [19, 7, 2, 6, 10, 21, 4, 13]\n",
      "test [8, 23, 0, 5, 1, 17, 15, 3]\n",
      "valid [18, 16, 14, 11, 20, 12, 9, 22]\n",
      "valid [5, 0, 1]\n",
      "start model training\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5453620553016663\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.375041127204895\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35189422965049744\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5407059192657471\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22671812772750854\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.43631190061569214\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37714821100234985\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.38939735293388367\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5406414866447449\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5453006625175476\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22666575014591217\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37498635053634644\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3770895004272461\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3893827795982361\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35184165835380554\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.4362601041793823\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3770308196544647\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37493160367012024\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5405765771865845\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.4362083077430725\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.545239269733429\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2266133725643158\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3517891466617584\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3893682360649109\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5451785326004028\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35173723101615906\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22656163573265076\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3893539309501648\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.4361572861671448\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37487760186195374\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37697285413742065\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5405129194259644\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22651022672653198\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5404493808746338\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5451186299324036\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37691524624824524\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.43610647320747375\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3893395960330963\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3748239278793335\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35168567299842834\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.4360559582710266\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37477049231529236\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5403863787651062\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3768579363822937\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22645904123783112\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35163429379463196\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5450589656829834\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.38932541012763977\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.4360054135322571\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3768005967140198\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22640807926654816\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5449994206428528\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.374717116355896\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.38931089639663696\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.54032301902771\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35158294439315796\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3767431080341339\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.38929635286331177\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5449395179748535\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22635628283023834\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.4359546899795532\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35153135657310486\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3746635317802429\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5402593016624451\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37460994720458984\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3892817497253418\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.43590396642684937\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37668558955192566\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5448796153068542\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2263045310974121\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35147982835769653\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5401955246925354\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.37455689907073975\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3892672657966614\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.35142824053764343\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5448197722434998\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.5401323437690735\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.4358532130718231\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.22625277936458588\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.376628041267395\n",
      "optimize/lv2_task/train/lv1_task/train loss_final 0.5267127156257629\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.31217893958091736\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.1092764139175415\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.3404698371887207\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.7004553079605103\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.5775406360626221\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.6332622170448303\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.22191546857357025\n",
      "optimize/lv2_task/train/lv1_task/test/lv0_task/train loss_final 0.22144770622253418\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.16265954077243805\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.30054447054862976\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.21302448213100433\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.09501440078020096\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.19113992154598236\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.23979322612285614\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.26031622290611267\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.13635049760341644\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.19112497568130493\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.09500598162412643\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.16264817118644714\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.13633976876735687\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.26030632853507996\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.300527960062027\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.23977705836296082\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.21300815045833588\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.13632923364639282\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3005114495754242\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.1911100298166275\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2397608608007431\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.16263677179813385\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.0949975997209549\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.21299178898334503\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.26029646396636963\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2129753977060318\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.19109505414962769\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3004949688911438\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.09498923271894455\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.23974469304084778\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.13631869852542877\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.16262540221214294\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2602865397930145\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3004784882068634\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.13630816340446472\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.23972852528095245\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2602766752243042\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.21295903623104095\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.16261403262615204\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.19108010828495026\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.0949808731675148\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.09497255831956863\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.1626027524471283\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.21294276416301727\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.13629771769046783\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.19106529653072357\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2397124469280243\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.26026690006256104\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.30046209692955017\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.09496425092220306\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.19105049967765808\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.21292655169963837\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.3004457354545593\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.2602570652961731\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.13628730177879333\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.16259151697158813\n",
      "optimize/lv2_task/train/lv1_task/train/lv0_task/train loss_final 0.23969636857509613\n"
     ]
    }
   ],
   "source": [
    "input_ = \"--task fmnist_lv2 --n_contexts 2 2  --n_iters 3 10 100 --k_batch_train 13 8 3  --n_batch_train 13 8 3 --architecture 2 28 1  --test_interval 5 --private \"\n",
    "args = get_args(input_.split())\n",
    "# print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[2, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1, 1], higher_flag=False, k_batch_test=[13, 8, 3, 2], k_batch_train=[13, 8, 3, 2], k_batch_valid=[13, 8, 3, 2], levels=4, log_interval=100, log_name='experiment', loss_logging_levels=[], lrs=[0.01, 0.01, 0.01, 0.01], model_type='CAVIA', n_batch_test=[13, 8, 3, 2], n_batch_train=[13, 8, 3, 2], n_batch_valid=[13, 8, 3, 2], n_contexts=[2, 2, 2], n_iters=[3, 10, 100, 1000], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='mnist+fmnist_lv3', test_interval=5, v_num=None, viz=False)\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "max_iters [3, 10, 100, 5]\n",
      "train [9, 12, 5, 21, 15, 19, 4, 17]\n",
      "test [22, 23, 14, 10, 11, 3, 8, 20]\n",
      "valid [16, 7, 6, 2, 0, 1, 13, 18]\n",
      "train [16, 22, 20, 17, 19, 11, 15, 1]\n",
      "test [7, 0, 21, 9, 14, 13, 5, 18]\n",
      "valid [12, 2, 3, 23, 6, 4, 8, 10]\n",
      "train [14, 15, 13, 0, 23, 12, 20, 8]\n",
      "test [11, 17, 5, 10, 16, 4, 22, 3]\n",
      "valid [19, 21, 9, 7, 1, 2, 6, 18]\n",
      "train [7, 3, 2]\n",
      "train [15, 4, 18, 16, 1, 9, 2, 6]\n",
      "test [21, 11, 3, 0, 20, 19, 13, 10]\n",
      "valid [22, 23, 8, 12, 14, 5, 7, 17]\n",
      "train [10, 18, 15, 1, 11, 23, 0, 17]\n",
      "test [16, 2, 3, 5, 6, 9, 21, 13]\n",
      "valid [19, 7, 22, 8, 4, 14, 20, 12]\n",
      "train [7, 6, 9, 11, 3, 20, 18, 5]\n",
      "test [4, 17, 1, 10, 0, 22, 15, 8]\n",
      "valid [16, 14, 23, 12, 2, 19, 13, 21]\n",
      "test [8, 5, 6]\n",
      "train [15, 4, 1, 11, 7, 17, 18, 13]\n",
      "test [0, 10, 22, 14, 12, 20, 2, 6]\n",
      "valid [19, 9, 3, 21, 5, 16, 8, 23]\n",
      "train [0, 13, 9, 11, 23, 5, 14, 3]\n",
      "test [6, 12, 21, 17, 8, 22, 10, 16]\n",
      "valid [4, 19, 15, 20, 2, 18, 7, 1]\n",
      "train [6, 22, 4, 17, 5, 18, 13, 11]\n",
      "test [1, 15, 12, 21, 20, 8, 9, 0]\n",
      "valid [10, 2, 19, 7, 3, 23, 16, 14]\n",
      "valid [1, 4, 0]\n",
      "train [20, 7, 4, 9, 8, 2, 5, 22]\n",
      "test [12, 1, 15, 10, 0, 18, 16, 14]\n",
      "valid [17, 19, 11, 23, 21, 3, 6, 13]\n",
      "train [9, 15, 21, 3, 19, 23, 6, 11]\n",
      "test [10, 20, 0, 1, 18, 12, 16, 2]\n",
      "valid [7, 22, 8, 5, 13, 4, 14, 17]\n",
      "train [9, 20, 13, 15, 18, 21, 10, 3]\n",
      "test [2, 7, 16, 17, 11, 23, 4, 14]\n",
      "valid [8, 19, 0, 22, 5, 1, 12, 6]\n",
      "train [2, 5, 0]\n",
      "train [17, 11, 14, 0, 8, 7, 4, 10]\n",
      "test [6, 3, 12, 9, 21, 20, 13, 2]\n",
      "valid [22, 5, 19, 16, 15, 18, 23, 1]\n",
      "train [1, 9, 11, 14, 17, 0, 12, 5]\n",
      "test [7, 23, 15, 2, 19, 4, 3, 20]\n",
      "valid [6, 8, 10, 16, 22, 18, 21, 13]\n",
      "train [21, 1, 3, 22, 12, 9, 14, 0]\n",
      "test [10, 13, 19, 15, 20, 18, 5, 7]\n",
      "valid [23, 11, 4, 8, 16, 6, 17, 2]\n",
      "test [3, 6, 8]\n",
      "train [18, 13, 15, 11, 2, 22, 5, 1]\n",
      "test [0, 12, 7, 19, 20, 14, 16, 21]\n",
      "valid [10, 6, 9, 8, 4, 17, 23, 3]\n",
      "train [6, 23, 9, 7, 10, 19, 15, 12]\n",
      "test [18, 22, 16, 21, 2, 11, 1, 3]\n",
      "valid [0, 13, 17, 14, 5, 8, 20, 4]\n",
      "train [15, 20, 9, 8, 1, 16, 10, 5]\n",
      "test [18, 0, 22, 12, 2, 19, 14, 4]\n",
      "valid [13, 17, 23, 3, 7, 21, 6, 11]\n",
      "valid [1, 7, 4]\n",
      "train ['fmnist_lv2', 'mnist_lv2']\n",
      "train [21, 3, 13, 1, 15, 23, 20, 14]\n",
      "test [11, 19, 16, 17, 5, 4, 18, 2]\n",
      "valid [8, 10, 12, 6, 0, 22, 7, 9]\n",
      "train [21, 23, 5, 17, 8, 7, 2, 12]\n",
      "test [18, 14, 0, 4, 15, 9, 6, 22]\n",
      "valid [16, 20, 10, 11, 13, 19, 3, 1]\n",
      "train [15, 5, 1, 14, 0, 7, 20, 4]\n",
      "test [18, 11, 17, 6, 22, 2, 8, 19]\n",
      "valid [12, 10, 13, 23, 16, 9, 3, 21]\n",
      "train [7, 2, 5]\n",
      "train [3, 16, 15, 23, 21, 9, 0, 5]\n",
      "test [4, 1, 2, 11, 12, 7, 8, 6]\n",
      "valid [17, 22, 14, 10, 20, 19, 18, 13]\n",
      "train [8, 4, 5, 22, 9, 16, 10, 23]\n",
      "test [18, 3, 12, 21, 20, 17, 11, 6]\n",
      "valid [13, 14, 2, 19, 15, 7, 1, 0]\n",
      "train [2, 0, 22, 18, 20, 5, 23, 13]\n",
      "test [15, 6, 8, 11, 9, 21, 12, 10]\n",
      "valid [16, 19, 4, 14, 3, 7, 17, 1]\n",
      "test [4, 1, 3]\n",
      "train [19, 11, 0, 13, 6, 17, 23, 10]\n",
      "test [21, 1, 18, 12, 5, 4, 3, 9]\n",
      "valid [2, 14, 22, 7, 15, 16, 8, 20]\n",
      "train [4, 8, 18, 3, 5, 2, 22, 7]\n",
      "test [21, 16, 0, 11, 9, 15, 20, 12]\n",
      "valid [19, 6, 1, 23, 14, 17, 10, 13]\n",
      "train [3, 1, 14, 5, 16, 19, 4, 6]\n",
      "test [18, 21, 9, 20, 22, 2, 11, 17]\n",
      "valid [10, 12, 0, 23, 13, 8, 7, 15]\n",
      "valid [8, 0, 6]\n",
      "train [9, 16, 21, 4, 20, 7, 6, 18]\n",
      "test [1, 3, 5, 23, 17, 11, 0, 15]\n",
      "valid [2, 19, 13, 8, 12, 22, 10, 14]\n",
      "train [19, 5, 23, 20, 12, 0, 16, 10]\n",
      "test [22, 17, 1, 21, 13, 9, 2, 11]\n",
      "valid [8, 14, 6, 18, 3, 15, 4, 7]\n",
      "train [4, 23, 12, 21, 22, 17, 13, 0]\n",
      "test [15, 14, 16, 5, 10, 6, 8, 11]\n",
      "valid [1, 19, 9, 3, 7, 20, 18, 2]\n",
      "train [4, 5, 6]\n",
      "train [0, 10, 18, 12, 7, 17, 2, 1]\n",
      "test [3, 19, 21, 9, 11, 23, 6, 22]\n",
      "valid [15, 8, 16, 5, 13, 4, 14, 20]\n",
      "train [14, 17, 2, 20, 7, 1, 12, 3]\n",
      "test [22, 18, 13, 16, 9, 4, 19, 8]\n",
      "valid [11, 6, 21, 5, 23, 15, 0, 10]\n",
      "train [18, 1, 8, 12, 17, 19, 13, 21]\n",
      "test [5, 16, 10, 4, 3, 11, 6, 7]\n",
      "valid [9, 2, 0, 14, 23, 20, 15, 22]\n",
      "test [3, 8, 0]\n",
      "train [13, 12, 0, 15, 4, 21, 10, 17]\n",
      "test [19, 16, 2, 18, 23, 1, 5, 6]\n",
      "valid [3, 7, 20, 9, 8, 14, 22, 11]\n",
      "train [19, 20, 12, 6, 3, 10, 21, 13]\n",
      "test [1, 22, 2, 16, 15, 14, 18, 8]\n",
      "valid [4, 17, 0, 23, 5, 11, 7, 9]\n",
      "train [6, 23, 14, 19, 21, 11, 7, 22]\n",
      "test [4, 17, 16, 0, 13, 10, 9, 18]\n",
      "valid [20, 12, 2, 3, 15, 8, 1, 5]\n",
      "valid [1, 7, 2]\n",
      "test ['fmnist_lv2', 'mnist_lv2']\n",
      "train [16, 4, 22, 9, 12, 10, 11, 13]\n",
      "test [15, 23, 0, 14, 1, 18, 17, 7]\n",
      "valid [5, 2, 8, 21, 20, 6, 3, 19]\n",
      "train [16, 20, 17, 5, 12, 9, 23, 0]\n",
      "test [1, 11, 4, 21, 10, 15, 19, 3]\n",
      "valid [13, 6, 18, 8, 7, 2, 14, 22]\n",
      "train [3, 10, 2, 11, 19, 18, 7, 20]\n",
      "test [4, 13, 5, 6, 0, 21, 1, 23]\n",
      "valid [15, 17, 16, 8, 12, 9, 22, 14]\n",
      "train [4, 0, 1]\n",
      "train [4, 17, 3, 11, 0, 23, 2, 9]\n",
      "test [6, 19, 12, 22, 7, 20, 10, 13]\n",
      "valid [21, 8, 14, 16, 15, 5, 1, 18]\n",
      "train [13, 19, 11, 16, 20, 21, 3, 7]\n",
      "test [23, 0, 8, 6, 18, 5, 4, 10]\n",
      "valid [2, 14, 1, 17, 12, 9, 15, 22]\n",
      "train [13, 23, 5, 19, 10, 18, 12, 2]\n",
      "test [3, 16, 0, 21, 7, 11, 15, 22]\n",
      "valid [9, 4, 17, 8, 6, 1, 14, 20]\n",
      "test [5, 2, 7]\n",
      "train [17, 22, 0, 5, 19, 1, 10, 2]\n",
      "test [18, 11, 21, 12, 7, 13, 6, 8]\n",
      "valid [16, 9, 15, 4, 20, 23, 14, 3]\n",
      "train [19, 12, 22, 21, 1, 2, 3, 6]\n",
      "test [17, 23, 11, 5, 14, 20, 7, 4]\n",
      "valid [15, 18, 9, 0, 8, 16, 10, 13]\n",
      "train [22, 6, 20, 17, 14, 3, 16, 11]\n",
      "test [23, 21, 5, 9, 8, 2, 0, 19]\n",
      "valid [4, 18, 12, 15, 10, 1, 13, 7]\n",
      "valid [3, 6, 8]\n",
      "train [18, 7, 11, 20, 0, 5, 8, 9]\n",
      "test [6, 16, 14, 4, 13, 19, 3, 2]\n",
      "valid [1, 22, 15, 23, 12, 17, 21, 10]\n",
      "train [7, 12, 5, 20, 14, 15, 23, 16]\n",
      "test [17, 2, 21, 19, 6, 8, 3, 4]\n",
      "valid [13, 18, 11, 9, 22, 10, 1, 0]\n",
      "train [13, 11, 17, 16, 3, 12, 15, 6]\n",
      "test [4, 5, 23, 1, 2, 18, 10, 9]\n",
      "valid [19, 0, 21, 22, 8, 20, 14, 7]\n",
      "train [8, 0, 4]\n",
      "train [19, 22, 8, 5, 1, 2, 20, 21]\n",
      "test [14, 16, 23, 4, 6, 10, 13, 0]\n",
      "valid [17, 9, 11, 18, 12, 7, 3, 15]\n",
      "train [0, 16, 23, 12, 22, 7, 10, 6]\n",
      "test [13, 20, 15, 2, 11, 5, 17, 18]\n",
      "valid [14, 9, 1, 3, 4, 21, 8, 19]\n",
      "train [1, 21, 7, 16, 20, 13, 0, 23]\n",
      "test [22, 6, 17, 11, 19, 18, 12, 4]\n",
      "valid [2, 14, 3, 10, 9, 15, 8, 5]\n",
      "test [3, 5, 2]\n",
      "train [23, 4, 13, 6, 2, 17, 10, 1]\n",
      "test [16, 19, 5, 20, 9, 0, 15, 7]\n",
      "valid [3, 22, 12, 18, 8, 21, 11, 14]\n",
      "train [20, 14, 22, 16, 18, 0, 13, 21]\n",
      "test [2, 6, 8, 11, 10, 5, 17, 12]\n",
      "valid [4, 7, 19, 3, 15, 9, 23, 1]\n",
      "train [12, 9, 2, 18, 15, 19, 13, 1]\n",
      "test [16, 4, 21, 0, 5, 10, 8, 17]\n",
      "valid [3, 23, 7, 20, 14, 6, 11, 22]\n",
      "valid [6, 7, 1]\n",
      "valid ['fmnist_lv2', 'mnist_lv2']\n",
      "start model training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b15beaf1cea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/main_huh.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# logger.log_hyperparams(hparams) # Commenting out b/c causing errors with logging hyperparameters of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Start train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/train_huh.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(hparams, logger)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m###############################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_Hierarchical_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mbase_model\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mget_base_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, task_list, level, optimizer, reset, return_outputs, prev_status, current_status, viz)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/lv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, level, status, optimizer, reset, return_outputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# evaluate on one mini-batch from test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# param_all[level] # for log_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_status\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Loss to be optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, task_list, level, optimizer, reset, return_outputs, prev_status, current_status, viz)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/lv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, level, status, optimizer, reset, return_outputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# evaluate on one mini-batch from test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# param_all[level] # for log_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_status\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Loss to be optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, task_list, level, optimizer, reset, return_outputs, prev_status, current_status, viz)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/lv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, level, status, optimizer, reset, return_outputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# evaluate on one mini-batch from test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# param_all[level] # for log_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_status\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Loss to be optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, task_list, level, optimizer, reset, return_outputs, prev_status, current_status, viz)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/lv'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, level, status, optimizer, reset, return_outputs)\u001b[0m\n\u001b[1;32m     78\u001b[0m                         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# evaluate on one mini-batch from test dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cur_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mcur_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0mfirst_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mfirst_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#filter(lambda p: p.grad is not None, parameters):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    202\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_ = \"--task mnist+fmnist_lv3 --n_contexts 2 2 2  --n_iters 3 10 100 1000 --k_batch_train 13 8 3 2 --n_batch_train 13 8 3 2 --architecture 2 28 1  --test_interval 5 --private \"\n",
    "args = get_args(input_.split())\n",
    "# print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1], higher_flag=False, k_batch_test=[10, 4], k_batch_train=[10, 4], k_batch_valid=[10, 4], levels=2, log_interval=100, log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[], lrs=[0.01, 0.01], model_type='CAVIA', n_batch_test=[10, 4], n_batch_train=[10, 4], n_batch_valid=[10, 4], n_contexts=[2], n_iters=[3, 20], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine_lv1', test_interval=5, v_num=None, viz=False)\n",
      "max_iters [3, 20]\n",
      "train [(0.990942339314793, 0.5761822607907845), (0.200864022049432, 3.0470616661964836), (0.864491338167939, 0.49007123908847783), (1.590786990501735, 1.648570950539833)]\n",
      "test [(2.2165305913463675, 0.9149233273574404), (4.178968939922067, 0.6670829901766624), (1.5315087778225691, 1.1509596754470768), (0.38460969962417735, 2.721172616281258)]\n",
      "valid [(3.0454635575417233, 2.224475608612444), (1.9352465823520764, 2.9867570806801083), (3.6867703148758855, 1.8807410959626114), (3.0980791841396598, 0.43823288784533293)]\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "start model training\n",
      "outer-loop idx 0 test loss 2.7514357566833496\n",
      "Saving model\n",
      "outer-loop idx 1 test loss 2.554349184036255\n",
      "Saving model\n",
      "outer-loop idx 2 test loss 2.51422381401062\n",
      "Saving model\n",
      "outer-loop idx 3 test loss 2.433903217315674\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "input_ = \"--task sine_lv1 --n_contexts 2 --n_iters 3 20 --k_batch_train 10 4 --n_batch_train 10 4 --architecture 1 28 1 --test_interval 5 --private \"\n",
    "args = get_args(input_.split())\n",
    "# print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[5, 4, 2], k_batch_train=[5, 4, 2], k_batch_valid=[5, 4, 2], levels=3, log_interval=100, log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[], lrs=[0.01, 0.01, 0.01], model_type='CAVIA', n_batch_test=[5, 4, 2], n_batch_train=[5, 4, 2], n_batch_valid=[5, 4, 2], n_contexts=[2, 2], n_iters=[3, 3, 20], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine+line_lv2', test_interval=5, v_num=None, viz=False)\n",
      "max_iters [3, 3, 20]\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "start model training\n",
      "outer-loop idx 0 test loss 21.913841247558594\n",
      "Saving model\n",
      "outer-loop idx 1 test loss 23.744075775146484\n",
      "Saving model\n",
      "outer-loop idx 2 test loss 27.17923355102539\n",
      "Saving model\n",
      "outer-loop idx 3 test loss 28.239700317382812\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_ = \"--task sine+line_lv2 --n_contexts 2 2 --n_iters 3 3 20 --k_batch_train 5 4 2 --n_batch_train 5 4 2 --architecture 1 28 1  --test_interval 5 --private \"\n",
    "args = get_args(input_.split())\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 8, 3, 6, 5, 4, 7, 1, 0, 9] [246, 79, 102, 120, 243, 22, 33, 270, 229, 29, 327, 26, 337, 159, 348, 308, 307, 142, 85, 199, 215, 266, 156, 153, 5, 285, 56, 261, 313, 112, 162, 40, 67, 343, 106, 15, 181, 72, 347, 147, 109, 345, 174, 267, 12, 44, 342, 188, 161, 82, 93, 320, 234, 105, 295, 275, 28, 311, 185, 51, 241, 202, 226, 42, 323, 0, 331, 224, 209, 182, 335, 171, 324, 32, 126, 9, 192, 289, 330, 169, 119, 89, 187, 259, 148, 149, 286, 341, 297, 306, 48, 318, 190, 66, 73, 31, 116, 132, 201, 256, 114, 37, 129, 248, 198, 304, 107, 269, 214, 276, 186, 196, 263, 123, 52, 65, 236, 336, 232, 55, 130, 223, 16, 207, 274, 136, 46, 314, 305, 1, 221, 325, 92, 81, 173, 137, 176, 39, 242, 143, 18, 63, 75, 326, 225, 47, 110, 218, 228, 298, 206, 340, 115, 195, 346, 83, 290, 152, 329, 154, 87, 212, 59, 244, 25, 13, 88, 128, 227, 35, 98, 205, 138, 99, 197, 265, 319, 41, 231, 193, 322, 36, 150, 53, 272, 80, 45, 222, 303, 204, 139, 315, 230, 19, 11, 69, 216, 145, 177, 54, 58, 10, 135, 252, 253, 84, 200, 165, 271, 127, 21, 43, 179, 2, 321, 14, 121, 141, 96, 344, 237, 316, 257, 301, 166, 219, 167, 239, 217, 284, 175, 76, 57, 178, 62, 334, 302, 103, 95, 20, 101, 338, 68, 90, 208, 64, 293, 158, 49, 61, 280, 134, 287, 292, 27, 91, 220, 260, 146, 140, 264, 6, 210, 278, 312, 249, 247, 310, 191, 233, 258, 111, 4, 77, 34, 118, 70, 317, 3, 24, 38, 17, 268, 30, 277, 94, 294, 279, 71, 300, 180, 86, 235, 251, 250, 131, 172, 281, 255, 125, 291, 333, 117, 168, 100, 78, 151, 213, 296, 299, 283, 328, 8, 74, 113, 288, 23, 211, 160, 189, 339, 163, 240, 50, 332, 254, 262, 184, 133, 157, 183, 273, 238, 194, 144, 164, 282, 122, 203, 104, 309, 124, 245, 60, 97, 108, 7, 155, 170] tensor([[0.1429, 0.7857],\n",
      "        [0.0000, 0.1786],\n",
      "        [0.7143, 0.4643]])\n"
     ]
    }
   ],
   "source": [
    "# from task.make_tasks_new import mnist2_task, mnist1_task\n",
    "\n",
    "\n",
    "keys = ['train', 'test', 'valid']\n",
    "def make_dict(vals):\n",
    "    return {k:v for (k,v) in zip(keys, vals)}\n",
    "\n",
    "from task.make_tasks_new import Task_sampler, Partial_Task_sampler\n",
    "from task.image_reconstruction_new import img_reconst_task_gen\n",
    "\n",
    "mnist2_fnc, input0_fnc_2d = img_reconst_task_gen('mnist')\n",
    "\n",
    "# def mnist2_fnc(label, idx, xy):\n",
    "#     dataset_label = (target == label) # level2 \n",
    "#     img = dataset_label[idx]          # level1 \n",
    "#     return img[xy]                    # level0\n",
    "\n",
    "mnist0_task = Partial_Task_sampler(mnist2_fnc, input0_fnc_2d)\n",
    "mnist1_task = Partial_Task_sampler(mnist0_task, None)\n",
    "mnist2_task = Task_sampler(mnist1_task, None)\n",
    "\n",
    "\n",
    "mnist2_task.pre_sample(make_dict([10,0,0]))\n",
    "labels, mnist1_tasks = mnist2_task.get_data('train')\n",
    "mnist1_Task_Sampler = mnist1_tasks[0]\n",
    "mnist1_Task_Sampler.pre_sample(make_dict([349,0,0]))\n",
    "idx, mnist0_tasks = mnist1_Task_Sampler.get_data('train')\n",
    "mnist0_Task_Sampler = mnist0_tasks[0]\n",
    "mnist0_Task_Sampler.pre_sample(make_dict([3,0,0]))\n",
    "xy, pixels = mnist0_Task_Sampler.get_data('train')\n",
    "\n",
    "print(labels, idx, xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets\n",
    "# datasets.FashionMNIST(os.path.join(os.getcwd(),'data'), train=True, transform=None, download=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torchvision.datasets as datasets\n",
    "\n",
    "# data_dir    = '/nobackup/users/benhuh/data/' \n",
    "# train_imgs = datasets.MNIST(data_dir, train=True, transform=[], download=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('HRL': conda)",
   "language": "python",
   "name": "python37464bithrlconda354877dd682d47658cade7a87f9d6c42"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
