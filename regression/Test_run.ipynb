{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from main_huh import main, get_args\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6009 (pid 36017), started 0:46:36 ago. (Use '!kill 36017' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-392456de3eb13b90\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-392456de3eb13b90\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'logs/experiment/' --host 0.0.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 30, 1], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[None, None, None], k_batch_train=[30, 2, 2], k_batch_valid=[None, None, None], levels=3, log_level_ctx=[True, True, True], log_level_loss=[True, True, True], log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', lrs=[0.02, 0.02, 0.03], model_type='CAVIA', n_batch_test=[None, None, None], n_batch_train=[30, 2, 2], n_batch_valid=[None, None, None], n_contexts=[2, 2], n_iters=[2, 2, 10], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine_linear_lv2', task_merge_flags=[True, True, True], test_intervals=[1, 1, 1], v_num=None, viz=False)\n",
      "level 1 cur_iter 0 test loss 5.673617362976074\n",
      "level 1 cur_iter 1 test loss 5.672937393188477\n",
      "level 1 cur_iter 0 test loss 10.881648063659668\n",
      "level 1 cur_iter 1 test loss 10.87969970703125\n",
      "level 1 cur_iter 0 test loss 6.128730297088623\n",
      "level 1 cur_iter 1 test loss 6.127988815307617\n",
      "level 1 cur_iter 0 test loss 9.185821533203125\n",
      "level 1 cur_iter 1 test loss 9.184408187866211\n",
      "level 2 cur_iter 0 test loss 7.656198501586914\n",
      "level 1 cur_iter 0 test loss 6.128730773925781\n",
      "level 1 cur_iter 1 test loss 6.127988815307617\n",
      "level 1 cur_iter 0 test loss 9.185821533203125\n",
      "level 1 cur_iter 1 test loss 9.184408187866211\n",
      "level 1 cur_iter 0 test loss 6.13410758972168\n",
      "level 1 cur_iter 1 test loss 6.132949352264404\n",
      "level 1 cur_iter 0 test loss 8.27872085571289\n",
      "level 1 cur_iter 1 test loss 8.276972770690918\n",
      "level 2 cur_iter 1 test loss 7.204961776733398\n",
      "level 1 cur_iter 0 test loss 8.27872085571289\n",
      "level 1 cur_iter 1 test loss 8.276972770690918\n",
      "level 1 cur_iter 0 test loss 6.13410758972168\n",
      "level 1 cur_iter 1 test loss 6.132949352264404\n",
      "level 1 cur_iter 0 test loss 7.676187038421631\n",
      "level 1 cur_iter 1 test loss 7.674191474914551\n",
      "level 1 cur_iter 0 test loss 6.102579116821289\n",
      "level 1 cur_iter 1 test loss 6.100493431091309\n",
      "level 2 cur_iter 2 test loss 6.88734245300293\n",
      "level 1 cur_iter 0 test loss 7.676186561584473\n",
      "level 1 cur_iter 1 test loss 7.674190521240234\n",
      "level 1 cur_iter 0 test loss 6.102579116821289\n",
      "level 1 cur_iter 1 test loss 6.100493431091309\n",
      "level 1 cur_iter 0 test loss 7.187254428863525\n",
      "level 1 cur_iter 1 test loss 7.1850690841674805\n",
      "level 1 cur_iter 0 test loss 6.245032787322998\n",
      "level 1 cur_iter 1 test loss 6.240987777709961\n",
      "level 2 cur_iter 3 test loss 6.7130279541015625\n",
      "level 1 cur_iter 0 test loss 7.187254905700684\n",
      "level 1 cur_iter 1 test loss 7.1850690841674805\n",
      "level 1 cur_iter 0 test loss 6.245033264160156\n",
      "level 1 cur_iter 1 test loss 6.240987777709961\n",
      "level 1 cur_iter 0 test loss 6.604197025299072\n",
      "level 1 cur_iter 1 test loss 6.594798564910889\n",
      "level 1 cur_iter 0 test loss 6.714221954345703\n",
      "level 1 cur_iter 1 test loss 6.711800575256348\n",
      "level 2 cur_iter 4 test loss 6.653299808502197\n",
      "level 1 cur_iter 0 test loss 6.6041975021362305\n",
      "level 1 cur_iter 1 test loss 6.594799041748047\n",
      "level 1 cur_iter 0 test loss 6.714221954345703\n",
      "level 1 cur_iter 1 test loss 6.711800575256348\n",
      "level 1 cur_iter 0 test loss 6.286721229553223\n",
      "level 1 cur_iter 1 test loss 6.283930778503418\n",
      "level 1 cur_iter 0 test loss 7.011660575866699\n",
      "level 1 cur_iter 1 test loss 6.989954948425293\n",
      "level 2 cur_iter 5 test loss 6.6369428634643555\n",
      "level 1 cur_iter 0 test loss 7.011660575866699\n",
      "level 1 cur_iter 1 test loss 6.989954948425293\n",
      "level 1 cur_iter 0 test loss 6.2867207527160645\n",
      "level 1 cur_iter 1 test loss 6.283931732177734\n",
      "level 1 cur_iter 0 test loss 7.269356727600098\n",
      "level 1 cur_iter 1 test loss 7.232137203216553\n",
      "level 1 cur_iter 0 test loss 5.915387153625488\n",
      "level 1 cur_iter 1 test loss 5.911276340484619\n",
      "level 2 cur_iter 6 test loss 6.571706771850586\n",
      "level 1 cur_iter 0 test loss 5.915387153625488\n",
      "level 1 cur_iter 1 test loss 5.911276817321777\n",
      "level 1 cur_iter 0 test loss 7.269356727600098\n",
      "level 1 cur_iter 1 test loss 7.232137203216553\n",
      "level 1 cur_iter 0 test loss 7.29329776763916\n",
      "level 1 cur_iter 1 test loss 7.236914157867432\n",
      "level 1 cur_iter 0 test loss 5.6000895500183105\n",
      "level 1 cur_iter 1 test loss 5.593219757080078\n",
      "level 2 cur_iter 7 test loss 6.415066719055176\n",
      "level 1 cur_iter 0 test loss 7.293296813964844\n",
      "level 1 cur_iter 1 test loss 7.236914157867432\n",
      "level 1 cur_iter 0 test loss 5.600089073181152\n",
      "level 1 cur_iter 1 test loss 5.59321928024292\n",
      "level 1 cur_iter 0 test loss 7.064803123474121\n",
      "level 1 cur_iter 1 test loss 6.98734712600708\n",
      "level 1 cur_iter 0 test loss 5.385207176208496\n",
      "level 1 cur_iter 1 test loss 5.369902610778809\n",
      "level 2 cur_iter 8 test loss 6.178624629974365\n",
      "level 1 cur_iter 0 test loss 7.064803123474121\n",
      "level 1 cur_iter 1 test loss 6.98734712600708\n",
      "level 1 cur_iter 0 test loss 5.385207653045654\n",
      "level 1 cur_iter 1 test loss 5.369902610778809\n",
      "level 1 cur_iter 0 test loss 6.661680221557617\n",
      "level 1 cur_iter 1 test loss 6.564647674560547\n",
      "level 1 cur_iter 0 test loss 5.273311614990234\n",
      "level 1 cur_iter 1 test loss 5.2467145919799805\n",
      "level 2 cur_iter 9 test loss 5.9056806564331055\n",
      "level 1 cur_iter 0 test loss 6.661680221557617\n",
      "level 1 cur_iter 1 test loss 6.564647674560547\n",
      "level 1 cur_iter 0 test loss 5.273311614990234\n",
      "level 1 cur_iter 1 test loss 5.246713638305664\n"
     ]
    }
   ],
   "source": [
    "%tb\n",
    "# input_ = \"--task sine_lv1 --n_contexts 2 --n_iters 5 100 --k_batch_train 25 5 --n_batch_train 25 5 --architecture 1 28 1 --private \"\n",
    "# input_ = \"--task sine_linear_lv2 --n_contexts 2 2 --n_iters 1 1 10 --k_batch_train 30 1 1  --architecture 1 30 1 --private \"\n",
    "input_ = \"--task sine_linear_lv2 --n_contexts 2 2 --n_iters 2 2 10 --k_batch_train 30 2 2  --architecture 1 30 1 --lrs 0.02 0.02 0.03 --log_level_loss True True True --log_level_ctx True True False --test_intervals 1 1 1 --private \"\n",
    "args = get_args(input_.split())\n",
    "# args.lrs = [0.02, 0.02, 0.03]\n",
    "# args.lrs = [0.1, 0.1, 0.1]\n",
    "# args.log_level_loss = [True, True, True]\n",
    "# args.log_level_ctx = [True, True, False]\n",
    "# args.test_intervals = [1,1,1]\n",
    "args.task_merge_flags = [True, True, True]\n",
    "# args.task_merge_flags = [False, False, False]\n",
    "\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 30, 30, 1], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[None, None, None], k_batch_train=[30, 4, 4], k_batch_valid=[None, None, None], levels=3, log_level_ctx=[True, True, True], log_level_loss=[True, True, True], log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', lrs=[0.02, 0.02, 0.03], model_type='CAVIA', n_batch_test=[None, None, None], n_batch_train=[30, 4, 4], n_batch_valid=[None, None, None], n_contexts=[2, 2], n_iters=[4, 8, 500], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine_linear_lv2', task_merge_flags=[True, True, True], test_intervals=[4, 8, 1], v_num=None, viz=False)\n",
      "level 1 cur_iter 0 test loss 24.812671661376953\n",
      "level 1 cur_iter 0 test loss 6.891848564147949\n",
      "level 1 cur_iter 0 test loss 7.849494934082031\n",
      "level 1 cur_iter 0 test loss 35.068477630615234\n",
      "level 1 cur_iter 0 test loss 7.966874122619629\n",
      "level 1 cur_iter 0 test loss 34.61101150512695\n",
      "level 1 cur_iter 0 test loss 25.225746154785156\n",
      "level 1 cur_iter 0 test loss 7.202874660491943\n",
      "level 2 cur_iter 0 test loss 18.750293731689453\n",
      "level 1 cur_iter 0 test loss 34.61101150512695\n",
      "level 1 cur_iter 0 test loss 7.966874122619629\n",
      "level 1 cur_iter 0 test loss 7.202874660491943\n",
      "level 1 cur_iter 0 test loss 25.225744247436523\n",
      "level 1 cur_iter 0 test loss 6.994155406951904\n",
      "level 1 cur_iter 0 test loss 7.844397068023682\n",
      "level 1 cur_iter 0 test loss 34.568058013916016\n",
      "level 1 cur_iter 0 test loss 25.10661506652832\n",
      "level 2 cur_iter 1 test loss 18.627580642700195\n",
      "level 1 cur_iter 0 test loss 6.994155406951904\n",
      "level 1 cur_iter 0 test loss 34.56806182861328\n",
      "level 1 cur_iter 0 test loss 7.844396591186523\n",
      "level 1 cur_iter 0 test loss 25.10661506652832\n",
      "level 1 cur_iter 0 test loss 6.917057991027832\n",
      "level 1 cur_iter 0 test loss 34.71323776245117\n",
      "level 1 cur_iter 0 test loss 7.820402145385742\n",
      "level 1 cur_iter 0 test loss 25.051013946533203\n",
      "level 2 cur_iter 2 test loss 18.62401580810547\n",
      "level 1 cur_iter 0 test loss 25.05101203918457\n",
      "level 1 cur_iter 0 test loss 7.820402145385742\n",
      "level 1 cur_iter 0 test loss 34.71324157714844\n",
      "level 1 cur_iter 0 test loss 6.917057991027832\n",
      "level 1 cur_iter 0 test loss 24.877580642700195\n",
      "level 1 cur_iter 0 test loss 6.898934364318848\n",
      "level 1 cur_iter 0 test loss 7.82505989074707\n",
      "level 1 cur_iter 0 test loss 34.95323944091797\n",
      "level 2 cur_iter 3 test loss 18.636417388916016\n",
      "level 1 cur_iter 0 test loss 7.82505989074707\n",
      "level 1 cur_iter 0 test loss 34.95323944091797\n",
      "level 1 cur_iter 0 test loss 24.877578735351562\n",
      "level 1 cur_iter 0 test loss 6.898934364318848\n",
      "level 1 cur_iter 0 test loss 6.897402763366699\n",
      "level 1 cur_iter 0 test loss 7.824549674987793\n",
      "level 1 cur_iter 0 test loss 35.087074279785156\n",
      "level 1 cur_iter 0 test loss 24.739654541015625\n",
      "level 2 cur_iter 4 test loss 18.634504318237305\n",
      "level 1 cur_iter 0 test loss 35.087074279785156\n",
      "level 1 cur_iter 0 test loss 7.824549674987793\n",
      "level 1 cur_iter 0 test loss 24.739654541015625\n",
      "level 1 cur_iter 0 test loss 6.897402286529541\n",
      "level 1 cur_iter 0 test loss 6.898138999938965\n",
      "level 1 cur_iter 0 test loss 35.12744140625\n",
      "level 1 cur_iter 0 test loss 24.67296600341797\n",
      "level 1 cur_iter 0 test loss 7.82136344909668\n",
      "level 2 cur_iter 5 test loss 18.62700843811035\n",
      "level 1 cur_iter 0 test loss 24.67296600341797\n",
      "level 1 cur_iter 0 test loss 35.12744140625\n",
      "level 1 cur_iter 0 test loss 6.898138999938965\n",
      "level 1 cur_iter 0 test loss 7.821363925933838\n",
      "level 1 cur_iter 0 test loss 6.902256965637207\n",
      "level 1 cur_iter 0 test loss 7.81294059753418\n",
      "level 1 cur_iter 0 test loss 35.11281204223633\n",
      "level 1 cur_iter 0 test loss 24.651222229003906\n",
      "level 2 cur_iter 6 test loss 18.616580963134766\n",
      "level 1 cur_iter 0 test loss 7.8129401206970215\n",
      "level 1 cur_iter 0 test loss 24.651222229003906\n",
      "level 1 cur_iter 0 test loss 35.11280822753906\n",
      "level 1 cur_iter 0 test loss 6.902256488800049\n",
      "level 1 cur_iter 0 test loss 7.803753852844238\n",
      "level 1 cur_iter 0 test loss 24.65470314025879\n",
      "level 1 cur_iter 0 test loss 35.061912536621094\n",
      "level 1 cur_iter 0 test loss 6.909446716308594\n",
      "level 2 cur_iter 7 test loss 18.60228729248047\n",
      "level 1 cur_iter 0 test loss 7.803753852844238\n",
      "level 1 cur_iter 0 test loss 35.061912536621094\n",
      "level 1 cur_iter 0 test loss 24.654701232910156\n",
      "level 1 cur_iter 0 test loss 6.909446716308594\n",
      "level 1 cur_iter 0 test loss 34.99536895751953\n",
      "level 1 cur_iter 0 test loss 7.793911933898926\n",
      "level 1 cur_iter 0 test loss 24.663888931274414\n",
      "level 1 cur_iter 0 test loss 6.920636177062988\n",
      "level 2 cur_iter 8 test loss 18.587753295898438\n",
      "level 1 cur_iter 0 test loss 6.9206366539001465\n",
      "level 1 cur_iter 0 test loss 24.66388702392578\n",
      "level 1 cur_iter 0 test loss 7.793911933898926\n",
      "level 1 cur_iter 0 test loss 34.99536895751953\n",
      "level 1 cur_iter 0 test loss 34.93172836303711\n",
      "level 1 cur_iter 0 test loss 24.658037185668945\n",
      "level 1 cur_iter 0 test loss 7.7842817306518555\n"
     ]
    }
   ],
   "source": [
    "# input_ = \"--task sine_lv1 --n_contexts 2 --n_iters 5 100 --k_batch_train 25 5 --n_batch_train 25 5 --architecture 1 28 1 --private \"\n",
    "# input_ = \"--task sine_linear_lv2 --n_contexts 2 2 --n_iters 2 2 10 --k_batch_train 30 2 2  --architecture 1 30 1 --lrs 0.02 0.02 0.03 --log_level_loss True True True --log_level_ctx True True False --test_intervals 1 1 1 --private \"\n",
    "input_ = \"--task sine_linear_lv2 --n_contexts 2 2 --n_iters 4 8 500 --k_batch_train 30 4 4  --architecture 1 30 30 1 --lrs 0.02 0.02 0.03 --log_level_loss True True True --log_level_ctx True True False --test_intervals 4 8 1 --task_merge_flags True True True --private \"\n",
    "args = get_args(input_.split())\n",
    "# args.lrs = [0.02, 0.02, 0.05]\n",
    "# args.loss_logging_levels = [0,1,2]\n",
    "# args.test_intervals = [4,8,1]\n",
    "\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 30, 30, 1], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[None, None, None], k_batch_train=[30, 4, 4], k_batch_valid=[None, None, None], levels=3, log_interval=100, log_level_ctx=[False, False, False], log_level_loss=[False, False, False, False], log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[0, 1, 2], lrs=[0.02, 0.02, 0.05], model_type='CAVIA', n_batch_test=[None, None, None], n_batch_train=[30, 4, 4], n_batch_valid=[None, None, None], n_contexts=[2, 2], n_iters=[4, 8, 500], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine_linear_lv2', task_merge_flags=[True, True, False], test_intervals=[4, 8, 1], v_num=None, viz=False)\n",
      "level 1 cur_iter 0 test loss 24.812671661376953\n",
      "level 1 cur_iter 0 test loss 6.891848564147949\n",
      "level 1 cur_iter 0 test loss 7.849494934082031\n",
      "level 1 cur_iter 0 test loss 35.068477630615234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-cc05b97eec5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/main_huh.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# directly get 'test-loss' without pre-training: zero-shot on super-task env.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupertask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#True) # grad_clip = hparams.clip )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# run(hparams, model, supertask)         # obsolete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, level, task_list, optimizer, reset, return_outputs, status, viz, iter_num)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtask_merge_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_merge_flags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#len(task_list) > task_merge_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmeta_eval_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_eval_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#             if status == viz:   #visualize_output(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mget_average_loss\u001b[0;34m(model, task_list, return_outputs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mmeta_eval\u001b[0;34m(self, task, task_idx, level, status, optimizer, reset, return_outputs, iter_num, task_merge_flag)\u001b[0m\n\u001b[1;32m    128\u001b[0m                         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_level_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# (level in self.log_level_loss),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                         log_ctx_flag = self.log_level_ctx[level]) #(level in self.log_level_ctx))\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtest_loss_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final test-loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, status, run_test, test_interval, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 loss, output = model.forward(level, task_batch, status = status, #current_status = current_status, \n\u001b[0;32m--> 239\u001b[0;31m                                                                 iter_num = cur_iter)    # Loss to be optimized\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, level, task_list, optimizer, reset, return_outputs, status, viz, iter_num)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtask_merge_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_merge_flags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#len(task_list) > task_merge_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmeta_eval_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_eval_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#             if status == viz:   #visualize_output(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mget_average_loss\u001b[0;34m(model, task_list, return_outputs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mmeta_eval\u001b[0;34m(self, task, task_idx, level, status, optimizer, reset, return_outputs, iter_num, task_merge_flag)\u001b[0m\n\u001b[1;32m    130\u001b[0m                         log_ctx_flag = self.log_level_ctx[level]) #(level in self.log_level_ctx))\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtest_loss_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final test-loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_loss_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(iter_num)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;31m# evaluate on one mini-batch from test-loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0msample_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, current_status = 'test' + current_status)    # test only 1 minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, level, task_list, optimizer, reset, return_outputs, status, viz, iter_num)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mtask_merge_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_merge_flags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#len(task_list) > task_merge_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmeta_eval_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_eval_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;31m#             if status == viz:   #visualize_output(outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mget_average_loss\u001b[0;34m(model, task_list, return_outputs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mmeta_eval\u001b[0;34m(self, task, task_idx, level, status, optimizer, reset, return_outputs, iter_num, task_merge_flag)\u001b[0m\n\u001b[1;32m    128\u001b[0m                         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_level_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# (level in self.log_level_loss),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                         log_ctx_flag = self.log_level_ctx[level]) #(level in self.log_level_ctx))\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtest_loss_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final test-loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, status, run_test, test_interval, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 loss, output = model.forward(level, task_batch, status = status, #current_status = current_status, \n\u001b[1;32m    239\u001b[0m                                                                 iter_num = cur_iter)    # Loss to be optimized\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlog_ctx_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m                         \u001b[0mfirst_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mfirst_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#filter(lambda p: p.grad is not None, parameters):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    202\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# input_ = \"--task sine_lv1 --n_contexts 2 --n_iters 5 100 --k_batch_train 25 5 --n_batch_train 25 5 --architecture 1 28 1 --private \"\n",
    "input_ = \"--task sine_linear_lv2 --n_contexts 2 2 --n_iters 4 8 500 --k_batch_train 30 4 4  --architecture 1 30 30 1 --private \"\n",
    "args = get_args(input_.split())\n",
    "args.lrs = [0.02, 0.02, 0.05]\n",
    "args.loss_logging_levels = [0,1,2]\n",
    "args.test_intervals = [4,8,1]\n",
    "args.task_merge_flags = [True, True, False]\n",
    "\n",
    "print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 50, 50, 50, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[30, 8, 8], k_batch_train=[30, 100, 100], k_batch_valid=[None, None, None], levels=3, log_interval=100, log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[0, 1, 2], lrs=[0.06, 0.03, 0.01], model_type='CAVIA', n_batch_test=[10, 4, 4], n_batch_train=[10, 8, 8], n_batch_valid=[None, None, None], n_contexts=[2, 2], n_iters=[4, 8, 500], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine_linear_lv2', test_intervals=[4, 8, 1], v_num=None, viz=False)\n",
      "level 2 cur_iter 0 test loss 19.97883415222168\n",
      "level 2 cur_iter 1 test loss 13.392863273620605\n",
      "level 2 cur_iter 2 test loss 17.035606384277344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a019eea4bc93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/main_huh.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# directly get 'test-loss' without pre-training: zero-shot on super-task env.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupertask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#True) # grad_clip = hparams.clip )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# run(hparams, model, supertask)         # obsolete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, level, task_list, optimizer, reset, return_outputs, prev_status, current_status, viz, iter_num)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtask_merge_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtask_merge_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mmodel_forward_single_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward_single_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#             if status == viz:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mget_average_loss\u001b[0;34m(model, task_list, return_outputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, task_idx, level, status, optimizer, reset, return_outputs, iter_num, task_merge_flag)\u001b[0m\n\u001b[1;32m    115\u001b[0m                         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mtest_loss_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final test-loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, run_test, test_interval, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# param_all[level] # for log_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Loss to be optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, level, task_list, optimizer, reset, return_outputs, prev_status, current_status, viz, iter_num)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtask_merge_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtask_merge_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mmodel_forward_single_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward_single_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#             if status == viz:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mget_average_loss\u001b[0;34m(model, task_list, return_outputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, task_idx, level, status, optimizer, reset, return_outputs, iter_num, task_merge_flag)\u001b[0m\n\u001b[1;32m    117\u001b[0m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mtest_loss_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final test-loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_loss_final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(iter_num)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;31m# evaluate on one mini-batch from test-loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, current_status = 'test' + current_status)    # test only 1 minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, level, task_list, optimizer, reset, return_outputs, prev_status, current_status, viz, iter_num)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mtask_merge_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtask_merge_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mmodel_forward_single_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh_level_foward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask_merge_flag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_average_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forward_single_task\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;31m#             if status == viz:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mget_average_loss\u001b[0;34m(model, task_list, return_outputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# Todo: Parallelize! see SubprocVecEnv: https://stable-baselines.readthedocs.io/en/master/guide/vec_envs.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mhigh_level_foward\u001b[0;34m(self, task, task_idx, level, status, optimizer, reset, return_outputs, iter_num, task_merge_flag)\u001b[0m\n\u001b[1;32m    115\u001b[0m                         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHigher_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigher_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                         \u001b[0mlog_loss_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_logging_levels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                         log_ctx_flag = (level in self.ctx_logging_levels))\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mtest_loss_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# final test-loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, dataloader, level, lr, max_iter, for_iter, optimizer, reset, prev_status, current_status, run_test, test_interval, device, Higher_flag, log_loss_flag, log_ctx_flag)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprev_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_iter\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Loss to be optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlog_ctx_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/Projects/cavia/regression/hierarchical_model.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m                         \u001b[0mfirst_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mfirst_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#filter(lambda p: p.grad is not None, parameters):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad_clip_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/HRL/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    202\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# input_ = \"--task sine_lv1 --n_contexts 2 --n_iters 5 100 --k_batch_train 25 5 --n_batch_train 25 5 --architecture 1 28 1 --private \"\n",
    "input_ = \"--task sine_linear_lv2 --n_contexts 2 2 --n_iters 4 8 500 --k_batch_train 30 100 100 --n_batch_train 10 8 8 --k_batch_test 30 8 8 --n_batch_test 10 4 4 --architecture 1 50 50 50 1 --private \"\n",
    "args = get_args(input_.split())\n",
    "args.lrs = [0.06, 0.03, 0.01]\n",
    "args.loss_logging_levels = [0,1,2]\n",
    "args.test_intervals = [4,8,1]\n",
    "\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1], higher_flag=False, k_batch_test=[25, 5], k_batch_train=[25, 5], k_batch_valid=[None, None], levels=2, log_interval=100, log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[0, 1], lrs=[0.01, 0.01], model_type='CAVIA', n_batch_test=[25, 5], n_batch_train=[25, 5], n_batch_valid=[None, None], n_contexts=[2], n_iters=[5, 100], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine_lv1', test_intervals=[2, 10], v_num=None, viz=False)\n",
      "level 1 cur_iter 0 test loss 5.649957180023193\n",
      "level 1 cur_iter 10 test loss 4.5288238525390625\n",
      "level 1 cur_iter 20 test loss 4.5710883140563965\n",
      "level 1 cur_iter 30 test loss 4.603878974914551\n",
      "level 1 cur_iter 40 test loss 4.568851470947266\n",
      "level 1 cur_iter 50 test loss 4.476817607879639\n",
      "level 1 cur_iter 60 test loss 4.47763729095459\n",
      "level 1 cur_iter 70 test loss 4.450722694396973\n",
      "level 1 cur_iter 80 test loss 4.40517520904541\n"
     ]
    }
   ],
   "source": [
    "# input_ = \"--task sine_lv1 --n_contexts 2 --n_iters 5 100 --k_batch_train 25 5 --n_batch_train 25 5 --architecture 1 28 1 --private \"\n",
    "input_ = \"--task sine_lv1 --n_contexts 2 --n_iters 5 100 --k_batch_train 25 5 --k_batch_test 25 5 --n_batch_train 25 5 --architecture 1 28 1 --private \"\n",
    "args = get_args(input_.split())\n",
    "args.lrs = [0.01, 0.01]\n",
    "args.loss_logging_levels = [0,1]\n",
    "args.test_intervals = [2,10]\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[1, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[None, None, None], k_batch_train=[5, 4, 2], k_batch_valid=[None, None, None], levels=3, log_interval=100, log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[], lrs=[0.01, 0.01, 0.01], model_type='CAVIA', n_batch_test=[None, None, None], n_batch_train=[5, 4, 2], n_batch_valid=[None, None, None], n_contexts=[2, 2], n_iters=[3, 3, 20], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='sine+line_lv2', test_interval=2, v_num=None, viz=False)\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "start model training\n",
      "outer-loop idx 0 test loss 15.94465446472168\n",
      "Saving model\n",
      "outer-loop idx 1 test loss 15.531441688537598\n",
      "Saving model\n",
      "outer-loop idx 2 test loss 15.267790794372559\n",
      "Saving model\n",
      "outer-loop idx 3 test loss 15.120172500610352\n",
      "Saving model\n",
      "outer-loop idx 4 test loss 15.027132034301758\n",
      "Saving model\n",
      "outer-loop idx 5 test loss 14.903217315673828\n",
      "Saving model\n",
      "outer-loop idx 6 test loss 14.743157386779785\n",
      "Saving model\n",
      "outer-loop idx 7 test loss 14.550373077392578\n",
      "Saving model\n",
      "outer-loop idx 8 test loss 14.317742347717285\n",
      "Saving model\n",
      "outer-loop idx 9 test loss 14.021892547607422\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "input_ = \"--task sine+line_lv2 --n_contexts 2 2 --n_iters 3 3 20 --k_batch_train 5 4 2 --n_batch_train 5 4 2 --architecture 1 28 1  --test_interval 2 --private \"\n",
    "args = get_args(input_.split())\n",
    "print(args)\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[2, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1], higher_flag=False, k_batch_test=[None, None], k_batch_train=[80, 3], k_batch_valid=[None, None], levels=2, log_interval=100, log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[], lrs=[0.01, 0.01], model_type='CAVIA', n_batch_test=[None, None], n_batch_train=[80, 3], n_batch_valid=[None, None], n_contexts=[2], n_iters=[3, 50], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='mnist_lv1', test_interval=5, v_num=None, viz=False)\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "start model training\n",
      "outer-loop idx 0 test loss 0.1079847440123558\n",
      "Saving model\n",
      "outer-loop idx 1 test loss 0.1063186526298523\n",
      "Saving model\n",
      "outer-loop idx 2 test loss 0.10525674372911453\n",
      "Saving model\n",
      "outer-loop idx 3 test loss 0.10382095724344254\n",
      "Saving model\n",
      "outer-loop idx 4 test loss 0.10239436477422714\n",
      "Saving model\n",
      "outer-loop idx 5 test loss 0.1009027287364006\n",
      "Saving model\n",
      "outer-loop idx 6 test loss 0.09948436170816422\n",
      "Saving model\n",
      "outer-loop idx 7 test loss 0.09787238389253616\n",
      "Saving model\n",
      "outer-loop idx 8 test loss 0.09666182845830917\n",
      "Saving model\n",
      "outer-loop idx 9 test loss 0.09540227800607681\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "input_ = \"--task mnist_lv1 --n_contexts 2  --n_iters 3 50 --k_batch_train 80 3  --n_batch_train 80 3 --architecture 2 28 1  --test_interval 5 --private \" \n",
    "args = get_args(input_.split())\n",
    "print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(architecture=[2, 28, 1], ctx_logging_levels=[], data_parallel=False, device=device(type='cpu'), encoders=[None, None, None], first_order=False, for_iters=[1, 1, 1], higher_flag=False, k_batch_test=[None, None, None], k_batch_train=[13, 8, 3], k_batch_valid=[None, None, None], levels=3, log_interval=100, log_name='experiment', log_save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs', loss_logging_levels=[], lrs=[0.01, 0.01, 0.01], model_type='CAVIA', n_batch_test=[None, None, None], n_batch_train=[13, 8, 3], n_batch_valid=[None, None, None], n_contexts=[2, 2], n_iters=[3, 10, 20], prefix='', save_path='/Users/huh/Dropbox (MIT)/Projects/cavia/regression', seed=42, task='mnist_lv2', test_interval=2, v_num=None, viz=False)\n",
      "max_iters [3, 10, 20]\n",
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "start model training\n",
      "outer-loop idx 0 test loss 0.1775292158126831\n",
      "Saving model\n",
      "outer-loop idx 1 test loss 0.12587930262088776\n",
      "Saving model\n",
      "outer-loop idx 2 test loss 0.10807500034570694\n",
      "Saving model\n",
      "outer-loop idx 3 test loss 0.10506954044103622\n",
      "Saving model\n",
      "outer-loop idx 4 test loss 0.10242012143135071\n",
      "Saving model\n",
      "outer-loop idx 5 test loss 0.100587397813797\n",
      "Saving model\n",
      "outer-loop idx 6 test loss 0.09992795437574387\n",
      "Saving model\n",
      "outer-loop idx 7 test loss 0.09912234544754028\n",
      "Saving model\n",
      "outer-loop idx 8 test loss 0.0986667275428772\n",
      "Saving model\n",
      "outer-loop idx 9 test loss 0.09793912619352341\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "input_ = \"--task mnist_lv2 --n_contexts 2 2  --n_iters 3 10 20 --k_batch_train 13 8 3  --n_batch_train 13 8 3 --architecture 2 28 1  --test_interval 2 --private \" \n",
    "args = get_args(input_.split())\n",
    "print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ = \"--task fmnist_lv2 --n_contexts 2 2  --n_iters 3 10 20 --k_batch_train 13 8 3  --n_batch_train 13 8 3 --architecture 2 28 1  --test_interval 2 --private \"\n",
    "# args = get_args(input_.split())\n",
    "# # print(args)\n",
    "# main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment\n",
      "/Users/huh/Dropbox (MIT)/Projects/cavia/regression/logs/experiment\n",
      "start model training\n",
      "outer-loop idx 0 test loss 0.20677191019058228\n",
      "Saving model\n",
      "outer-loop idx 1 test loss 0.17832714319229126\n",
      "Saving model\n",
      "outer-loop idx 2 test loss 0.15636873245239258\n",
      "Saving model\n",
      "outer-loop idx 3 test loss 0.14081716537475586\n",
      "Saving model\n",
      "outer-loop idx 4 test loss 0.1317259669303894\n",
      "Saving model\n",
      "outer-loop idx 5 test loss 0.1292368471622467\n",
      "Saving model\n",
      "outer-loop idx 6 test loss 0.12862595915794373\n",
      "Saving model\n",
      "outer-loop idx 7 test loss 0.1280030608177185\n",
      "Saving model\n",
      "outer-loop idx 8 test loss 0.1278388947248459\n",
      "Saving model\n",
      "outer-loop idx 9 test loss 0.12675592303276062\n",
      "Saving model\n",
      "outer-loop idx 10 test loss 0.12668149173259735\n",
      "Saving model\n",
      "outer-loop idx 11 test loss 0.12497693300247192\n",
      "Saving model\n",
      "outer-loop idx 12 test loss 0.12514226138591766\n",
      "Saving model\n",
      "outer-loop idx 13 test loss 0.12321189045906067\n",
      "Saving model\n",
      "outer-loop idx 14 test loss 0.12328482419252396\n",
      "Saving model\n",
      "outer-loop idx 15 test loss 0.12137649953365326\n",
      "Saving model\n",
      "outer-loop idx 16 test loss 0.12155210971832275\n",
      "Saving model\n",
      "outer-loop idx 17 test loss 0.11921876668930054\n",
      "Saving model\n",
      "outer-loop idx 18 test loss 0.11958914995193481\n",
      "Saving model\n",
      "outer-loop idx 19 test loss 0.11691072583198547\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "input_ = \"--task mnist+fmnist_lv3 --n_contexts 2 2 2  --n_iters 2 4 8 20 --k_batch_train 13 4 3 2 --n_batch_train 13 4 3 2 --architecture 2 28 1  --test_interval 1 --private \"\n",
    "args = get_args(input_.split())\n",
    "# print(args)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 8, 3, 6, 5, 4, 7, 1, 0, 9] [246, 79, 102, 120, 243, 22, 33, 270, 229, 29, 327, 26, 337, 159, 348, 308, 307, 142, 85, 199, 215, 266, 156, 153, 5, 285, 56, 261, 313, 112, 162, 40, 67, 343, 106, 15, 181, 72, 347, 147, 109, 345, 174, 267, 12, 44, 342, 188, 161, 82, 93, 320, 234, 105, 295, 275, 28, 311, 185, 51, 241, 202, 226, 42, 323, 0, 331, 224, 209, 182, 335, 171, 324, 32, 126, 9, 192, 289, 330, 169, 119, 89, 187, 259, 148, 149, 286, 341, 297, 306, 48, 318, 190, 66, 73, 31, 116, 132, 201, 256, 114, 37, 129, 248, 198, 304, 107, 269, 214, 276, 186, 196, 263, 123, 52, 65, 236, 336, 232, 55, 130, 223, 16, 207, 274, 136, 46, 314, 305, 1, 221, 325, 92, 81, 173, 137, 176, 39, 242, 143, 18, 63, 75, 326, 225, 47, 110, 218, 228, 298, 206, 340, 115, 195, 346, 83, 290, 152, 329, 154, 87, 212, 59, 244, 25, 13, 88, 128, 227, 35, 98, 205, 138, 99, 197, 265, 319, 41, 231, 193, 322, 36, 150, 53, 272, 80, 45, 222, 303, 204, 139, 315, 230, 19, 11, 69, 216, 145, 177, 54, 58, 10, 135, 252, 253, 84, 200, 165, 271, 127, 21, 43, 179, 2, 321, 14, 121, 141, 96, 344, 237, 316, 257, 301, 166, 219, 167, 239, 217, 284, 175, 76, 57, 178, 62, 334, 302, 103, 95, 20, 101, 338, 68, 90, 208, 64, 293, 158, 49, 61, 280, 134, 287, 292, 27, 91, 220, 260, 146, 140, 264, 6, 210, 278, 312, 249, 247, 310, 191, 233, 258, 111, 4, 77, 34, 118, 70, 317, 3, 24, 38, 17, 268, 30, 277, 94, 294, 279, 71, 300, 180, 86, 235, 251, 250, 131, 172, 281, 255, 125, 291, 333, 117, 168, 100, 78, 151, 213, 296, 299, 283, 328, 8, 74, 113, 288, 23, 211, 160, 189, 339, 163, 240, 50, 332, 254, 262, 184, 133, 157, 183, 273, 238, 194, 144, 164, 282, 122, 203, 104, 309, 124, 245, 60, 97, 108, 7, 155, 170] tensor([[0.1429, 0.7857],\n",
      "        [0.0000, 0.1786],\n",
      "        [0.7143, 0.4643]])\n"
     ]
    }
   ],
   "source": [
    "# from task.make_tasks_new import mnist2_task, mnist1_task\n",
    "\n",
    "\n",
    "keys = ['train', 'test', 'valid']\n",
    "def make_dict(vals):\n",
    "    return {k:v for (k,v) in zip(keys, vals)}\n",
    "\n",
    "from task.make_tasks_new import Task_sampler, Partial_Task_sampler\n",
    "from task.image_reconstruction_new import img_reconst_task_gen\n",
    "\n",
    "mnist2_fnc, input0_fnc_2d = img_reconst_task_gen('mnist')\n",
    "\n",
    "# def mnist2_fnc(label, idx, xy):\n",
    "#     dataset_label = (target == label) # level2 \n",
    "#     img = dataset_label[idx]          # level1 \n",
    "#     return img[xy]                    # level0\n",
    "\n",
    "mnist0_task = Partial_Task_sampler(mnist2_fnc, input0_fnc_2d)\n",
    "mnist1_task = Partial_Task_sampler(mnist0_task, None)\n",
    "mnist2_task = Task_sampler(mnist1_task, None)\n",
    "\n",
    "\n",
    "mnist2_task.pre_sample(make_dict([10,0,0]))\n",
    "labels, mnist1_tasks = mnist2_task.get_data('train')\n",
    "mnist1_Sampler = mnist1_tasks[0]\n",
    "mnist1_Sampler.pre_sample(make_dict([349,0,0]))\n",
    "idx, mnist0_tasks = mnist1_Sampler.get_data('train')\n",
    "mnist0_Sampler = mnist0_tasks[0]\n",
    "mnist0_Sampler.pre_sample(make_dict([3,0,0]))\n",
    "xy, pixels = mnist0_Sampler.get_data('train')\n",
    "\n",
    "print(labels, idx, xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision import datasets\n",
    "# datasets.FashionMNIST(os.path.join(os.getcwd(),'data'), train=True, transform=None, download=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import torchvision.datasets as datasets\n",
    "\n",
    "# data_dir    = '/nobackup/users/benhuh/data/' \n",
    "# train_imgs = datasets.MNIST(data_dir, train=True, transform=[], download=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('HRL': conda)",
   "language": "python",
   "name": "python37464bithrlconda354877dd682d47658cade7a87f9d6c42"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
